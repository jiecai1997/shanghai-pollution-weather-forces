{
    "collab_server" : "",
    "contents" : "---\ntitle: \"hw3RMD\"\nauthor: \"Jie Cai\"\ndate: \"9/14/2017\"\noutput:\n  html_document: default\n  word_document: default\n---\n\n#### 1. Chapter 7, Problem 23. In your answer, include the 95% confidence interval for the slope, and explain what the interval reveals about the relationship between duration and waiting time. Describe in a few sentences whether or not you think the regression assumptions are plausible based on residual plots (you don't need to include the plots). For the part of the question about prediction bands, construct a 95% prediction interval for the waiting time until the next eruption if the duration of the previous one was 4 minutes. This is the only prediction interval you need to report. \n\n```{r ex0723: scatterplot}\n#read in file\ndf0723 <- read.csv('ex0723.csv')\n\n#attach dataset so we can refer directly to variable names\nattach(df0723)\n\n# plot simple scatterplot between X and Y\nplot(x = Duration, y = Interval, xlab = \"Duration of Old Eruptions (mins)\", ylab = \"Duration until Subsequent Eruption (mins)\", main = \"Yellowstone Old Feithful Geyser Eruption Times and Intervals\")\n```\n\n```{r ex0723: linear regression model}\n#fit linear regression model to data\nreg0723 = lm(Interval ~ Duration, data = df0723)\n\n#view results of regression\nsummary(reg0723)\n\n#get 95% CI for coefficients \nconfint(reg0723)\n```\nEstimated Intercept (B0): 33.8282\nEstimated Intercept (B0) Standard Error: 2.2618\nEstimated Slope (B1): 10.7410\nEstimated Slope (B1) Standard Error: 0.6263\nResidual Standard Error: 6.683\nR^2: 0.7369\n\ny = 10.7410x + 33.8282\n\nThe estimated slope (or B1 value) and its 95% CI indicates that for every 1 minute increase in the old eruption duration, we are 95% confident that the average duration of subsequent eruptions will increase somewhere between 9.49 and 11.98 minutes, though the most accurate slope estimate is 10.74 minutes. The estimated B0 value indicates that we expect the average duration of subsequent eruption of a 0-minute old eruption to be 33.8282 minutes. This is a extrapolation, since no eruptions have a duration of 0 minutes.  \n\nThe residual SE is 6.683, meaning that we should expect the eruption interval to deviate 6.683 minutes from the estimated means at any old eruption time. The R^2 value of 0.7369 means that 73.69% of the variation in eruption interval times can be explained by regression line.\n\n```{r ex0723: residuals}\n#plot residual graph, adding a horizontal line at 0\nplot(y = reg0723$residual, x=Duration, ylab = \"Residuals\", main = \"Plot of Residuals\")\nabline(0,0)\n\n#normal quantile plot of residuals to check normality claim\nqqnorm(reg0723$residual, ylab = \"Residuals\", main = \"Normal Quantile Plot of Residuals\")\nabline(0,6.683)\n```\n\nLooking at the residual plots above, there doesn't seem to be a noticable trend in the residuals and the residual values follow the QQplot slope quite linearly, which helps with the assumption that our y values are distributed normally around the x values. We can also assume that each of the eruptions are independent of each other, while linearity can be observed from the linear scatterplot above. Since all of these assumptions are met, we can go ahead and use the linear regression model above.\n\n```{r ex0723: prediction}\n#make new prediction\nnewtimes0723 = c(4.0)\nnewdata0723 = data.frame(Duration = newtimes0723)\n\n#95%CI for estimated interval (individual)\npredict.lm(reg0723, newdata0723, interval = \"prediction\")\n```\nUsing the linear regression model above, we can estimate with 95% confidence that an old eruption time of 4.0 minutes will have a duration that's between 63.4631 minutes and 90.12108 minutes until its next eruption.\n\n\n#### 2. Chapter 7, Problem 29. In your answer, make sure you include the output from the regression model including the estimated intercept, slope, residual standard error, and R^2 . Also include and interpret a 95% confidence interval that addresses the main question of interest in the problem. Finally, be sure to include evidence that you checked the fit of the model. If you are unhappy with the regression assumptions for these data, you can state that (with evidence) but go ahead and use the results anyways. \n\n```{r ex0729: scatterplot}\n#read in file\ndf0729 <- read.csv('ex0729.csv')\n\n#attach dataset so we can refer directly to variable names\nattach(df0729)\n\n# plot simple scatterplot between X and Y\nplot(x = Mass, y = Tcell, xlab = \"Mean Stone Mass (g)\", ylab = \"T-cell Response (mm)\", main = \"Male Black Wheateres Stone Mass and T-cell Response\")\n```\n\n```{r ex0729: linear regression model}\n#fit linear regression model to data\nreg0729 = lm(Tcell ~ Mass, data = df0729)\n\n#view results of regression\nsummary(reg0729)\n\n#get 95% CI for coefficients \nconfint(reg0729)\n```\nEstimated Intercept (B0): 0.08750\nEstimated Intercept (B0) Standard Error: 0.07868\nEstimated Slope (B1): 0.03282\nEstimated Slope (B1) Standard Error: 0.01064\nResidual Standard Error: 0.08102\nR^2: 0.3336\n\ny = 0.03282x + 0.08750\n\nThe estimated slope (or B1 value) and its 95% CI indicates that for every 1 gram increase in stone masses, we are 95% confident that the average T-cell response will increase by 0.03282 will increase somewhere between 0.01054860 and 0.05509438 mm, though the most accurate slope estimate is 0.03282 mm. The estimated B0 value indicates that we expect the average T-cell response of a bird who carries rocks of 0 grams to be 0.08750 mm. This is a extrapolation, since all birds measured in the study carried rocks weighing 4 grams or above.   \n\nThe residual SE is 0.08102, meaning that we should expect measured T-cell responses of individuals to deviate 0.08102mm from the estimated means at any mass. The R^2 value of 0.3336 means that 33.36% of the variation in T-cell responses can be explained by regression line.\n\n```{r ex0729: residuals}\n#plot residual graph, adding a horizontal line at 0\nplot(y = reg0729$residual, x=Mass, ylab = \"Residuals\", main = \"Plot of Residuals\")\nabline(0,0)\n\n#normal quantile plot of residuals to check normality claim\nqqnorm(reg0729$residual, ylab = \"Residuals\", main = \"Normal Quantile Plot of Residuals\")\nabline(0,0.08102)\n```\n\nLooking at the residual plots above, there doesn't seem to be a noticable trend in the residuals and the residual values follow the QQplot slope quite linearly, which helps with the assumption that our y values are distributed normally around the x values. We can also assume that each of the stone masses of birds are independent of each other, while linearity can be observed from the linear scatterplot above. Since all of these assumptions are met, we can go ahead and use the linear regression model above.\n\n#### 3. Chapter 8, Problem 17. \n#### a) Use scatterplots of the raw data, along with trial and error, to determine transformations of Y = Ragwort by dry mass and of X = Flea beetle load that will produce an approximate linear relationship.\n```{r ex0817: scatterplots}\n#read in file\ndf0817 <- read.csv('ex0817.csv')\n\n#attach dataset so we can refer directly to variable names\nattach(df0817)\n\n# plot scatterplot between X and Y, no transformations\nplot(x = Load, y = Mass, xlab = \"Flea Beetle Load\", ylab = \"Ragwort Mass\", main = \"Flea Beetle Load VS Ragwort Mass (x,y)\")\n\n# plot scatterplot between logX and Y after transformation\nplot(x = log(Load), y = Mass, xlab = \"Flea Beetle Load\", ylab = \"Ragwort Mass\", main = \"Flea Beetle Load VS Ragwort Mass (logx,y)\")\n\n# plot scatterplot between logX and Y after transformation\nplot(x = Load, y = log(Mass), xlab = \"Flea Beetle Load\", ylab = \"Ragwort Mass\", main = \"Flea Beetle Load VS Ragwort Mass (x,logy)\")\n\n# plot scatterplot between logX and logY after transformations\nplot(x = log(Load), y = log(Mass), xlab = \"Flea Beetle Load\", ylab = \"Ragwort Mass\", main = \"Flea Beetle Load VS Ragwort Mass (x,y)\")\n```\n\nThe original X, Y graph between Mass and Load will not produce a linear relationship, so it's better that we try to fit a regression model with some sort of transformation.\n\nOf the three other plots above, the (x, logy) transformation would seem to produce the the best linear relationship. The other graphs seem to have a greater curvature in their slopes and a greater variation in Y values across different X values, so a linear regression would not work well on them.\n\n### b) Fit a linear regression model of the transformation scale.\n```{r 0817: linear regression model}\n#fit linear regression model to data\nreg0817 = lm((log(Mass) ~ Load), data = df0817)\n\n#view results of regression\nsummary(reg0817)\n\n#get 95% CI for coefficients \nconfint(reg0817)\n```\nEstimated Intercept (B0): 2.035158 \nEstimated Intercept (B0) Standard Error: 0.574492\nEstimated Slope (B1): -0.006539\nEstimated Slope (B1) Standard Error: 0.001028\nResidual Standard Error: 1.65\nR^2: 0.7568\n\ny = -0.006539x + 2.035158\n\ne^-0.006539 = 0.99348233273 -1 = -0.00651766726\ne^-0.008760191 = 0.99127806767 -1 = -0.00872193232\ne^-0.004318129 = 0.99569118071 -1 = -0.00430881928\n\nThe estimated slope (or B1 value) and its 95% CI indicates that for every 1 unit increase in the flea beetle load, we are 95% confident that the average dry mass of ragworts will decrease somewhere between -0.43% and 0.87%, though the mean decrease will be by 0.65%. \n\nThe R^2 value of 0.7568 means that 75.68% of the variation in ragworts dry mass can be explained by the linear regression model above. \n\n### c) Look at the residual plot. Do you want to try other transformations? What do you suggest?\n```{r ex0817: residual graphs}\n#plot residual graph, adding a horizontal line at 0\nplot(y = reg0817$residual, x=Load, ylab = \"Residuals\", main = \"Plot of Residuals\")\nabline(0,0)\n\n#normal quantile plot of residuals to check normality claim\nqqnorm(reg0817$residual, ylab = \"Residuals\", main = \"Normal Quantile Plot of Residuals\")\nabline(0,1.65)\n```\n\nLooking at the residual plots above, smaller X values have a larger Y residual values while larger Y values have smaller Y residual values. The qqplot further shows that the residuals are not constant over the quantiles. \nA possible tranformation that could result in a more linear regression could be (x^2, y) or any other variation of powers and square roots.\n\n\n#### 4. Chapter 8, Problem 24. In addition to the plot, include the output of the regression that predicts (possibly transformed) respiratory rates from (possibly transformed) age, as well as evidence that the model fits the assumptions reasonably well. Demonstrate the usefulness of the model by providing 95% prediction intervals for the rate for three individual children: a 1 month old, an 18 months old, and a 29 months old.\n\n```{r ex0824: scatterplots}\n#read in file\ndf0824 <- read.csv('ex0824.csv')\n\n#attach dataset so we can refer directly to variable names\nattach(df0824)\n\n# plot scatterplot between X and Y, no transformations\nplot(x = Age, y = Rate, xlab = \"Child Age (Months)\", ylab = \"Respiratory Rates (Breaths/Min)\", main = \"Childen and Respiratory Rates (x,y)\")\n\n# plot scatterplot between logx and y\nplot(x = log(Age), y = Rate, xlab = \"Child Age (Months)\", ylab = \"Respiratory Rates (Breaths/Min)\", main = \"Childen and Respiratory Rates (logx,y)\")\n\n# plot scatterplot between logx and y\nplot(x = Age, y = log(Rate), xlab = \"Child Age (Months)\", ylab = \"Respiratory Rates (Breaths/Min)\", main = \"Childen and Respiratory Rates (x,logy)\")\n\n# plot scatterplot between logx and y\nplot(x = log(Age), y = log(Rate), xlab = \"Child Age (Months)\", ylab = \"Respiratory Rates (Breaths/Min)\", , main = \"Childen and Respiratory Rates (logx,logy)\")\n```\n\nAfter observing the 4 graphs above, the (x, logy) transformation seems the most fitting for a linear regression model. We will create the LRM below.\n\n```{r 0824: linear regression model}\n#fit linear regression model to data\nreg0824 = lm((log(Rate) ~ Age), data = df0824)\n\n#view results of regression\nsummary(reg0824)\n\n#get 95% CI for coefficients \nconfint(reg0824)\n```\nEstimated Intercept (B0): 3.8451185\nEstimated Intercept (B0) Standard Error: 0.0126277\nEstimated Slope (B1): -0.0190090\nEstimated Slope (B1) Standard Error: 0.0007357\nResidual Standard Error: 0.1964\nR^2: 0.5201\n\ny = -0.0190090x + 3.8451185\n\ntransformed (B1) % interpretations:\ne^-0.0190090 = 0.98117053166 - 1 = -0.01882946834\ne^-0.02045369 = 0.97975406783 - 1 = -0.02024593217\ne^-0.01756423 = 0.98258912193 - 1 = -0.0174108780\n\nThe estimated slope (or B1 value) and its 95% CI indicates that for every 1 month increase in age, we are 95% confident that the average T-cell response will decrease between 1.741% and 2.025%, though on average it should decrease by 1.883%.\n\nThe residual SE is 0.1964, meaning that we should expect measured T-cell responses of individuals to deviate 0.1964% from the estimated respiration rate. The R^2 value of 0.5201 means that 52.01% of the variation in respiratory rates can be explained by regression line.\n\n```{r ex0817: resididual graphs}\n#plot residual graph, adding a horizontal line at 0\nplot(y = reg0824$residual, x=Age, ylab = \"Residuals\", main = \"Plot of Residuals\")\nabline(0,0)\n\n#normal quantile plot of residuals to check normality claim\nqqnorm(reg0824$residual, ylab = \"Residuals\", main = \"Normal Quantile Plot of Residuals\")\nabline(0,0.1964)\n```\n\nLooking at the residual plots above, there doesn't seem to be a noticable trend in the residuals and the residual values follow the QQplot slope quite linearly, which helps with the assumption that our y values are distributed normally around the x values. We can also assume that each of the children's measures are independent of each other, while linearity can be observed from the linear scatterplot above. Since all of these assumptions are met, we can go ahead and use the linear regression model above.\n\n```{r ex0824: prediction for new ages}\n#make new prediction for duration of 4.0 minutes\nnewdata0824 = data.frame(Age = c(1, 18, 29))\n\n#95%CI for estimated interval (individual)\npred = predict.lm(reg0824, newdata0824, interval = \"prediction\")\nconf = predict.lm(reg0824, newdata0824, interval = \"confidence\")\npred\n\n# plotting\nplot(x = newdata0824$Age, y = pred[,\"fit\"], type = 'l', \n     main = \"Prediction and Confidence Intervals\", xlab = \"Age\", ylab = \"Rate\")\n# first plot the fitted values\nlines(x = newdata0824$Age, pred[,\"lwr\"], col = \"blue\") # plotting lower bound for prediction interval\nlines(x = newdata0824$Age, pred[,\"upr\"], col = \"blue\") # plotting upper bound for prediction interval\nlines(x = newdata0824$Age, conf[,\"lwr\"], col = \"red\")  # plotting lower bound for confidence interval\nlines(x = newdata0824$Age, conf[,\"upr\"], col = \"red\")  # plotting upper bound for confidence interval\n\nlegend(\"topright\", legend = c(\"Fit\", \"Confidence\", \"Prediction\"), \n       col = c(\"black\",\"red\",\"blue\"), lty = c(1,1,1)) # putting a legend\n```\n\nLooking at our graph above, we are 95% confident that the mean respiratory rate of any age should fall between the condifence bands, while we are 95% confident that the the respiratory rate of any individual of any age should fall between the prediction bands.\n\nSpecifically, we can make predictions about respiration rates of babies aged at 1 month, 18 months and 29 months based on our linear regression model above:\nWe are 95% confident that a baby aged 1 month old will have a respiratory rate between 31.17 breaths/min and 4.21 breaths/min.\nWe are 95% confident that a baby aged 18 month old will have a respiratory rate between 22.58 breaths/min and 48.86 breaths/min.\nWe are 95% confident that a baby aged 29 month old will have a respiratory rate between 18.30 breaths/min and 39.67 breaths/min.\n\n#### 5. Chapter 8, Problem 25. Include the output from the final regression model that you used, as well as evidence that the model fits the assumptions reasonably well. Also include the 95% prediction interval based on your final model. \n\n```{r ex0825: scatterplot with Palm Beach}\n#read in file\ndf0825 <- read.csv('ex0825.csv')\n\n#attach dataset so we can refer directly to variable names\nattach(df0825)\n\n#simple scatterplot with palm beach dataset\nplot(x = Bush2000, y = Buchanan2000, xlab = \"Bush Votes\", ylab = \"Buchanan Votes\", main = \"Bush Votes VS Buchanan Votes in Florida (w/ Palm Beach)\")\n```\n```{r ex0825: }\n# make new dataframe with all observations except that of palm beach\ndf0825noPB <- df0825[1:66,]\n\n#attach dataset so we can refer directly to variable names\nattach(df0825noPB)\n\n# plot scatterplot between X and Y\nplot(x = Bush2000, y = Buchanan2000, xlab = \"Bush Votes\", ylab = \"Buchanan Votes\", main = \"Bush Votes VS Buchanan Votes in Florida (w/o Palm Beach, (x,y))\")\n\n# plot scatterplot between logX and Y\nplot(x = log(Bush2000), y = Buchanan2000, xlab = \"Bush Votes\", ylab = \"Buchanan Votes\", main = \"Bush Votes VS Buchanan Votes in Florida (w/o Palm Beach, (logx,y))\")\n\n# plot scatterplot between X and logY\nplot(x = Bush2000, y = log(Buchanan2000), xlab = \"Bush Votes\", ylab = \"Buchanan Votes\", main = \"Bush Votes VS Buchanan Votes in Florida (w/o Palm Beach, (x,logy))\")\n\n# plot scatterplot between logX and logY\nplot(x = log(Bush2000), y = log(Buchanan2000), xlab = \"Bush Votes\", ylab = \"Buchanan Votes\", main = \"Bush Votes VS Buchanan Votes in Florida (w/o Palm Beach, (logx,logy))\")\n```\n\n```{r ex0825: linear regression model}\n#fit linear regression model to data\nreg0825noPB = lm(log(Buchanan2000) ~ log(Bush2000), data = df0825noPB)\n\n#view results of regression\nsummary(reg0825noPB)\n\n#get 95% CI for coefficients \nconfint(reg0825noPB)\n```\nEstimated Intercept (B0): -2.34149\nEstimated Intercept (B0) Standard Error: 0.35442\nEstimated Slope (B1): 0.73096\nEstimated Slope (B1) Standard Error: 0.03597\nResidual Standard Error: 0.4198\nR^2: 0.8658\n\ny = 0.73096x + -2.34149\n\ntransformed (B1) % interpretations:\n\nThe estimated slope (or B1 value) and its 95% CI indicates that for every 1% increase in Bush notes, we are 95% confident that the average Buchanan Votes will increase between 0.66% and 0.80%, though on average it should increase by 0.73%.\n\nThe residual SE is 0.4198, meaning that we should expect the Buchanan votes to deviate 0.42% from the estimated number of Buchanan votes. The R^2 value of 0.8658 means that 86.58% of the variation in Buchanan votes can be explained by regression line.\n\n\n```{r ex0825: residual graphs}\n#plot residual graph, adding a horizontal line at 0\nplot(y = reg0825noPB$residual, x=log(Bush2000), ylab = \"Residuals\", main = \"Plot of Residuals\")\nabline(0,0)\n\n#normal quantile plot of residuals to check normality claim\nqqnorm(reg0825noPB$residual, ylab = \"Residuals\", main = \"Normal Quantile Plot of Residuals\")\nabline(0,0.4198)\n```\n\nLooking at the residual plots above, there doesn't seem to be a noticable trend in the residuals and the residual values follow the QQplot slope quite linearly, which helps with the assumption that our y values are distributed normally around the x values. We can also assume that each of the county's votes are independent of each other, while linearity can be observed from the linear scatterplot above. Since all of these assumptions are met, we can go ahead and use the linear regression model above.\n\n```{r ex0825: prediction}\n#make new prediction with # of Bush votes Palm Beach recieved\nnewdf0825 = data.frame(Bush2000 = c(152846))\n\n#95%CI for estimated interval (individual)\npredict.lm(reg0825noPB, newdf0825, interval = \"prediction\")\n```\nGiven our linear prediction model above, we are 95% confident that Palm Beach (with 152846 votes for Bush) should have between 251 and 1399 votes for Buchanan if it were to follow our regression. However, we can see that this is not the case, as in actuality there were 3407 votes casted for Buchanan, so we can say that this isn't a very normal occasion.\n\nIf we take the difference between the estimated Palm Beach votes and the actual Palm Beach votes, and assuming that this difference accounts for the votes that should have gone to Al Gore, we can estimate that Al Gore should have recieved between 1008 and 3156 votes from Palm Beach.",
    "created" : 1513187887372.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2045247518",
    "id" : "CC268EC",
    "lastKnownWriteTime" : 1506435826,
    "last_content_update" : 1506435826,
    "path" : "~/Documents/DUKE/Sophomore/Semester1/STA210/hw/hw3/hw3RMD.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}