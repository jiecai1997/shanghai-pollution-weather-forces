{
    "collab_server" : "",
    "contents" : "---\ntitle: \"hw4RMD\"\nauthor: \"Jie Cai\"\ndate: \"10/02/2017\"\noutput: html_document\n---\n```{r import}\nlibrary(lattice)\n```\n\n### 1. Chapter 9, Problem 12\n#### a) Draw a matrix of scatterplots for the mammal brain weight data with all the variables transformed to their log.\n```{r ex0912: a}\n#read in file\ndf0912 = read.csv('Ex0912.csv')\n\n#attach dataset so we can refer directly to variable names\nattach(df0912)\n\n#log all variables\nlogBody = log(Body)\nlogBrain = log(Brain)\nlogGestation = log(Gestation)\nlogLitter = log(Litter)\n\n#create scatterplot matrix\npairs(~logBrain+logBody+logGestation+logLitter,data=df0912, main=\"Species Scatterplot Matrix\")\n```\n\n#### b) Fit the multiple linear regression of log brain weight on log body weight, log gestation, and log litter size. Report the output from the regression model (include a table with coefficients and SEs, their associated confidence intervals, and somehwere in the text or table the estimated regression standard deviation and R^2).\n```{r ex0912: b}\nlm0912 = lm(logBrain ~ logBody + logGestation + logLitter)\nsummary(lm0912)\nconfint(lm0912)\nexp(confint(lm0912))\n```\n\n#### c) Does the relationship between log brain weight and litter size appear to be any better or any worse (more like a straight line) than the relationship between log brain weight and log litter size?\n```{r ex0912: c}\nlm0912.2 = lm (logBrain ~ Litter)\nsummary(lm0912.2)\nlm0912.3 = lm (logBrain ~ logLitter)\nsummary(lm0912.3)\n```\n\nLooking at the outputs above, the low R^2 values of both linear regressions show that neither transformation would resolve in a great linear regression model that can explain the variation in Brain Weights. However, the (logLitter, logBrain) transformation produces a slightly higher value of 0.4134, which would make a better fit for the model.\n\n### 2. Chapter 9, Problem 12 (Continued)\n#### d) Fit the regression model with log(brain size) on log(body weight), log(gestation) and litter size on its natural scale. Report the output of the model (include a table with coeffcients and SEs, their associated confidence intervals, and somewhere in the text or table the estimated regression standard deviation and R^2 ). \n```{r ex0912: d}\nlm0912.4 = lm(logBrain ~ logBody + logGestation + Litter)\nsummary(lm0912.4)\n2^(confint(lm0912.4))\nexp(confint(lm0912.4))\n```\n\n#### e) Provide an interpretation of each of the coefficients from the regression in Part D on the natural scale of brain weight and each predictor. Include 95% confidence intervals in your interpretations. \n\nlogBody - When we double body weight, we expect the mean brain weight to increase by 48.92%, and are 95% confident that this mean brain weight will increase between 42.38% and 55.77%.\n\nlogGestation - When we double gestation, we expect the mean brain weight to increase by 35.62%, and are 95% confident that this mean brain weight will increase between 12.32% and 63.77%.\n\nlitter - For every 1 unit increase in litter size, we expect the median brain weight to increase by 0.89%, and are 95% confident that this median brain weight will increase between 0.82% and 0.97%.\n\n#### f) Based on the quality of the residual plots and the value of R^2 , which model do you prefer: the one in Part B or the one in Part D? If you decide that you are ambivalent between the two models based on these measures of model fit, explain which one you would prefer for interpretability. \n\n```{r ex0912: f}\nplot(y = lm0912$residual, x = logBody, ylab = \"Residuals\", main = \"logBody VS logLitter Residuals\")\nabline(0,0)\nplot(y = lm0912$residual, x = logGestation, ylab = \"Residuals\", main = \"logBody VS logGestation Residuals\")\nabline(0,0)\nplot(y = lm0912$residual, x = logLitter, ylab = \"Residuals\", main = \"logBody VS logLitter Residuals\")\nabline(0,0)\nplot(y = lm0912.4$residual, x = Litter, ylab = \"Residuals\", main = \"logBody VS Litter Residuals\")\nabline(0,0)\n\nqqnorm(lm0912$residual, ylab = \"Residuals\", main = \"QQPlot of logLitter Residuals\")\nabline(0, 0.4748)\nqqnorm(lm0912.4$residual, ylab = \"Residuals\", main = \"QQPlot of Litter Residuals\")\nabline(0, 0.4756)\n```\n(logLitter, logBrain) R^2: 0.4748\n(Litter, logBrain) R^2: 0.9535\n\nSince the only difference between the linear models in part B and D is the litter transformation, we will only analyze residual plots against the litter predictor.\nThe R^2 and the residual plots give us contradictory proof about which transformation is more fitting.\nFor the (logLitter, logBrain) transformation, the R^2 value is quite low, but its residuals show random chance errors. For the (Litter, logBrain) transformation, the R^2 value is near perfect, but its residuals' variance change drastically with the x values. The qqnorm plots for both transformations are around the same.\n\nFor interpretation purposes, it's more convinient to use the (Litter, logBrain) tranformation. This way, we can say express litter size changes in units, and brain weight changes as percentages. \n\n### 3. Chapter 9, Problem 20\n#### Use a statistical computer program to fit a model for the mean winning speed as a function of year and the track condition factor. Submit a data analysis write-up for your answers. Be sure to include the following in your story: the model you ultimately decided to use, a justication for that model (e.g., why you chose certain transformations and why you decided the final model is reasonable to use based on residual diagnostics), the relevant regression output (includes: a table with coefficients and SEs, and p-values or confidence intervals; and somewhere in the text or table the estimated regression standard deviation and R^2 ), your interpretation of the results in the context of the questions of interest, and any potential limitations of the analysis. Make sure that you explain any interaction effects or quadratic effects included in the model. \n\n```{r ex0920}\n#read in file\ndf0920 = read.csv('Ex0920.csv')\n\n#attach dataset so we can refer directly to variable names\nattach(df0920)\n\n#exploratory data analysis\nplot(x = Year, y = Speed, xlab = \"Year\", ylab = \"Speed\", main = \"Year VS Speed\")\nboxplot(Speed~Condition, data = df0920, xlab = \"Condition\", ylab = \"Speed\", main = \"Condition VS Spped\")\n\n#log Speed: transform because of non-constant variance\nlogSpeed = log(Speed)\n#year^2: tranform because of quadratic relationship with year\nyearCentered = (Year - mean(Year))\nyearCentered2 = (yearCentered)^2\nYear2 = Year^2\n\n#look for interaction effects between speed and condtiion\nxyplot(logSpeed ~ Year | Condition, data = df0920)\n#similar slope for each plot, no strong evidence of interaction between speed and condition\n\n#dummy variables for categorial data (category)\nn = nrow(df0920)\n\nfast = rep(0, n)\nfast[Condition == \"fast\"] = 1\n\ngood = rep(0, n)\ngood[Condition == \"good\"] = 1\n\nslow = rep(0, n)\nslow[Condition == \"slow\"] = 1\n\n#multiple linear regression model without transformations\nlm0920 = lm(Speed~Year + fast + good + slow, data = df0920)\nsummary(lm0920)\n\n#CI intervals for coefficients\nconfint(lm0920)\n#exponentiate for interpretation\nexp(confint(lm0920))\n\n#plot residual plots to check assumptions\nplot(lm0920$resid, x = Year, ylab = \"Residuals\", main = \"Residuals against Year\")\nabline (0,0)\nboxplot(lm0920$resid~Condition, ylab = \"Residuals\", main = \"Residuals against Condition\")\nqqnorm(lm0920$resid, ylab = \"Residuals\")\nabline(0, 0.6505)\n#non-random residual trend for continuous predictors and different residual variance amongst categorical predictors. not a good fit\n\n#multiple linear regression model with tranformations above\nlm0920.2 = lm(logSpeed~ Year + Year2 + fast + good + slow, data = df0920)\nsummary(lm0920.2)\n\n#CI intervals for coefficients\nconfint(lm0920.2)\n#exponentiate for interpretation\nexp(confint(lm0920.2))\n\n#plot residual plots to check assumptions\nplot(lm0920.2$resid, x = Year, ylab = \"Residuals\")\nabline (0,0)\nboxplot(lm0920.2$resid~Condition, ylab = \"Residuals\")\nqqnorm(lm0920.2$resid, ylab = \"Residuals\")\nabline(0, 0.0105)\n# random residual trend for continuous predictors and similar residual variance amongst categorical predictors. good fit\n\n# plot year^2 + years to graphically show the \nnewdata = data.frame(Year = Year, Year2 = Year2, good = 0, fast = 0)\n\npred = predict(lm0920.2, newdata = newdata)\nplot(x = Year, y = pred, main = \"Years^2+Year VS Speed\")\n```\n\nVariable Analysis: \n\nfast: We expect the speed with a fast track to be 103.13% of the speed with a slow track, holding all other factors constant. We are 95% confident that this mean speed will between 102.57% and 103.70%.\n\ngood: We expect the speed with a good track to be 102.11% of the speed with a slow track, holding all other factors constant. We are 95% confident that this mean difference will between 101.28% and 102.94%.\n\nIt's difficult to explain the Year^2 + Year variable since it doesn't increase/decrease linearly, so we used the graph above to show its relationship with speed.\n\nOverall Analysis:\n\nFor our regression above, we plotted logSpeed against Year^2 + Years and Track Conditions (as indicator variables, with slow as the baseline). We logged the Y variable because it has nonsconstant variance, and squared the X variable as it produced a quadratic looking scatterplot initally. After analysing the nicely distributed residual plots of the tranformed regression, we can conclude that the assumptions for a linear regression are met. The individual variable analysis are above. One limitation of this model is that it cannot accurately predict speeds for years outside of the data range, as it is assuming a quadratic relationship purely based on the points inside the data range. The years is the quadratic relationship in this context. As for interaction effects, there doesn't seem to any significant interactions between Year and Track condition, so there was no need to create a new interaction variable.\n\n### 4. Chapter 10, Problem 15. \n#### Reconsider the old Faithful eruption durations and intervals in Display 7.14. Fit the regression of Interval on Duration and Day treated as a factor (include 7 indicator variables to distinguish the eight days). Obtain the analysis of variance table, and then fit the regression of interval on duration alone to obtain of variance table for this reduced model. Use the quantities listed in the tables to construct an F-statistic for the test of wehther any difference in mean intervals is due to the particular day of recording. Find the p-value (>.05, .01-.05, <0.1?), and write a conclusion.\n\n```{r ex1015}\n#read in file\ndf1015 = read.csv('Ex1015.csv')\n\n#attach dataset so we can refer directly to variable names\nattach(df1015)\n\n#exploratory data analysis\nplot(x = Duration, y = Interval, xlab = \"Duration\", ylab = \"Interval\", main = \"Duration VS Interval\")\nboxplot(Interval~Date, data = df1015, xlab = \"Day\", ylab = \"Interval\", main = \"Day VS Interval\")\n#scatterplot against continuous variable seems pretty linear, no need to transform\n\n#look for interaction effects between duration and date\nxyplot(Interval ~ Duration | Date, data = df0920)\n#similar slope for each plot, no strong evidence of interaction between speed and condition\n\n#dummy variables for categorial data (date)\nn = nrow(df1015)\n\ndate1 = rep(0, n)\ndate1[Date == 1] = 1\n\ndate2 = rep(0, n)\ndate2[Date == 2] = 1\n\ndate3 = rep(0, n)\ndate3[Date == 3] = 1\n\ndate4 = rep(0, n)\ndate4[Date == 4] = 1\n\ndate5 = rep(0, n)\ndate5[Date == 5] = 1\n\ndate6 = rep(0, n)\ndate6[Date == 6] = 1\n\ndate7 = rep(0, n)\ndate7[Date == 7] = 1\n\ndate8 = rep(0, n)\ndate8[Date == 8] = 1\n\n#multiple linear regression model including Dates\nlm1015 = lm(Interval~Duration + date1 + date2 + date3 + date4 + date5 + date6 + date7 + date8, data = df1015)\n#multiple linear regression model excluding Dates\nlm1015.2 = lm(Interval~Duration, data = df1015)\n\nanova(lm1015, lm1015.2)\n```\n\nF-Value: 0.2086\nP-Value: 0.9828\n\nThe F-value resulting from the ANOVA test between the model with and without Dates is very high (F = 0.9828), and its resulting P-value is also very high (p=0.9828, much higher than 0.05), meaning there's not much difference between the 2 models. This means that there is Date does not have a significant effect on the Interval times of the Old Faithful eruptions.\n\n### 5. Chapter 10, Problem 29. \n#### Analyze the data and write a brief statistical report to see whether and to what extent black males were paid less than nonblack males in the same region and with the same levels of education and expierence. Look at the interaction effects between Race and Region.\n\n```{r ex1029}\n#read in file\ndf1029 = read.csv('Ex1029.csv')\n\n#attach dataset so we can refer directly to variable names\nattach(df1029)\n\n#exploratory data analysis\nplot(x = Education, y = Wage, xlab = \"Education\", ylab = \"Wage\", main = \"Education VS Wage\")\nplot(x = Experience, y = Wage, xlab = \"Experience\", ylab = \"Wage\", main = \"Experience VS Wage\")\nboxplot(Wage~Black, data = df0920, xlab = \"Condition\", ylab = \"Wage\", main = \"Black (Race) VS Wage\")\nboxplot(Wage~SMSA, data = df0920, xlab = \"SMSA\", ylab = \"Wage\", main = \"SMSA VS Wage\")\nboxplot(Wage~Region, data = df0920, xlab = \"Region\", ylab = \"Wage\", main = \"SMSA VS Wage\")\n\n#log Wage: transform because of non-constant variance\nlogWage = log(Wage)\n\n#look for interaction effects between race and region\nbwplot(logWage ~ Black | Region, data = df1029)\n#similar slope for each plot, no strong evidence of interaction between speed and condition. But we will make a interaction variable below \n\n#dummy variables for categorial data (category)\nn = nrow(df1029)\n\nblack = rep(0, n)\nblack[Black == \"Yes\"] = 1\n\nnonBlack = rep(0, n)\nnonBlack[Black == \"Yes\"] = 1\n\nurban = rep(0, n)\nurban[SMSA == \"Yes\"] = 1\n\nnotUrban = rep(0, n)\nnotUrban[SMSA == \"No\"] = 1\n\nnotUrban = rep(0, n)\nnotUrban[SMSA == \"No\"] = 1\n\nNE = rep(0, n)\nNE[Region == \"NE\"] = 1\n\nMW = rep(0, n)\nMW[Region == \"MW\"] = 1\n\nS = rep(0, n)\nS[Region == \"S\"] = 1\n\nW = rep(0, n)\nW[Region == \"W\"] = 1\n\n#multiple linear regression model including Dates\nlm1015 = lm(logWage~Education + Experience + as.factor(Black) + as.factor(SMSA) + as.factor(Region) + as.factor(Black)*as.factor(Region), data = df1015)\nsummary(lm1015)\nconfint(lm1015)\n\n#check for residuals\nplot(lm1015$resid, x = Education, ylab = \"Residuals\", main = \"Residuals against Education\")\nabline (0,0)\nplot(lm1015$resid, x = Experience, ylab = \"Residuals\", main = \"Residuals against Expierence\")\nabline (0,0)\nboxplot(lm1015$resid~Black, ylab = \"Residuals\", main = \"Residuals against Race\")\nboxplot(lm1015$resid~SMSA, ylab = \"Residuals\", main = \"Residuals against SMSA\")\nboxplot(lm1015$resid~Region, ylab = \"Residuals\", main = \"Residuals against Region\")\nqqnorm(lm1015$resid, ylab = \"Residuals\")\nabline(0, 0.5314)\n```\n\nOverall Analysis: \n\nFor our regression above, we plotted logWage against Education, Expierence, Race (as indicator variables, with non-white as the baseline), SMSA (as indicator variables, with non-urban as the baseline), Region (as indivator variables, with NW as the baseline) as well as Race*Region as an interactive variable. We decided to log the Y variable because of its nonconstant variance, while we left the X variables unchanged since they did not produce any quadratic looking trends. Looking at the interactions between Race and Region, there doesn't seem to be any significant interactions - but since the question seems to have a strong emphasis on this relationship we will create an interactive variable, and use it to analyze wage differences between blacks and non-blacks of different regions (holding all other variables constant). \n\nEven after the tranformation to help with linearity assumptions, the tranformed graph doesn't seem to be a very good linear regression fit. It has a R value of 0.5314, meaning that the model can only explain 53.14% of the variation in wage. Furthermore, the residual plots of the tranformed graph also seem to have a variance that increases with Education. Though the model is not perfect, the numbers make it easy for us for us to explain some of the wage differences, which are shown specifically below.\n\nRegion Analysis:\n\n- e^Black = diff between black and white in MW (baseline region)\nIn the MidWest region (baseline), we expect an average black male (with average education and expierence) to have an income that's 21.39% less than that of an average white Male. We are 95% confident that this average income decrease from an average non-black male to an average black male is between 16.54% and 25.95%.\n\n- e^Black+Black*NE = diff between black and white in NE\nIn the NorthEast region, we expect an average Black Male (with average education and expierence) to have an income that's 19.59% less than that of an average non-black male. We are 95% confident that this average income decreases from an average non-black male to an average black male is between 7.15% and 30.36%.\n\n- e^Black+Black*S = diff between black and white in S\nIn the South Region, we expect an average Black Male (with average education and expierence) to have an income that's 21.13% less than that of an average non-black male. We are 95% confident that this average income decreases from an average non-black male to an average black male is between 9.47% and 30.61%.\n\n- e^Black+Black*W = diff between black and white in W\nIn the West Region, we expect an average Black Male (with average education and expierence) to have an income that's 17.62% less than that of an average non-black male. We are 95% confident that this average income decreases from an average non-black male to an average black male is between 3.34% and 29.78%.\n",
    "created" : 1513199528408.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1660317262",
    "id" : "E7A5720B",
    "lastKnownWriteTime" : 1507318708,
    "last_content_update" : 1507318708,
    "path" : "~/Documents/DUKE/Sophomore/Semester1/STA210/hw/hw4/hw4RMD.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}